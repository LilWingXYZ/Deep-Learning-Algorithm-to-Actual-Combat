{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence to Sequence + Attention\n",
    "\n",
    "自动翻译"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://img.huaiwen.me/20190122124610.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@部分代码和图片来自官方tutorials https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "teacher_forcing_ratio = 0.5\n",
    "hidden_size = 256\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder\n",
    "![](http://img.huaiwen.me/20190122124745.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input)\n",
    "        output, hidden = self.gru(embedded.view(1,1,-1), hidden)\n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(1,1,self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder\n",
    "![](http://img.huaiwen.me/20190122125045.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        \n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1,1,-1)\n",
    "        output = F.relu(embedded)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.out(output[0])\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 带Attention的Decoder\n",
    "![](http://img.huaiwen.me/20190122125145.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "        \n",
    "        # attention 权重\n",
    "        # [0.1, 0.7, 0.2]\n",
    "        attn_weights = F.softmax(self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        # 加权累加attention\n",
    "        # [10, 2, 3]\n",
    "        # [1, 1.4, 0.6]\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))\n",
    "        \n",
    "        # 讲input 和 attention 之后的值混合\n",
    "        # [1,2,3] + [1, 1.4, 0.6]\n",
    "        # [[1,2,3],[1, 1.4, 0.6]]\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        # 大小，变成了正常的大小\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seq2seq.data import prepare_data, tensors_from_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dumping model to file cache /tmp/jieba.cache\n",
      "Dump cache file failed.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/huaiwen/anaconda3/lib/python3.6/site-packages/jieba/__init__.py\", line 152, in initialize\n",
      "    _replace_file(fpath, cache_file)\n",
      "PermissionError: [Errno 1] Operation not permitted: '/tmp/tmp267fvrb0' -> '/tmp/jieba.cache'\n",
      "Loading model cost 0.953 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 20294 sentence lpairs\n",
      "Trimmed to 637 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "chi 1038\n",
      "eng 799\n",
      "['我 對 音樂有 興趣 。', 'i am interested in music .']\n"
     ]
    }
   ],
   "source": [
    "input_lang, output_lang, pairs = prepare_data('eng', 'chi', True)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['她 是 个 合格 的 护士 。', 'she is qualified as a nurse .']\n"
     ]
    }
   ],
   "source": [
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_decoder = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 迭代训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from seq2seq.utils import time_since\n",
    "import torch.optim as optim\n",
    "from seq2seq.plot import mat_plot, show_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    # input_tensor 输入： 中文\n",
    "    # target_tensor 输出： 英语\n",
    "    encoder_hidden = encoder.init_hidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    # 输入句子长度\n",
    "    input_length = input_tensor.size(0)\n",
    "    # 输出句子长度\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "    # 你 是 一个 好人\n",
    "    for ei in range(input_length):\n",
    "        # 输入一个字，以及上一个隐层值\n",
    "        encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    # decoder的解码\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    # 随机进行训练矫正\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # 把ground-truth当做下一步的输入\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # 把ground-truth 放进去\n",
    "\n",
    "    else:\n",
    "        # 把上一步的结果，当做下一步的输入\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # 把上一步预测的top 1 放进去\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_iters(input_lang, output_lang, pairs, encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0\n",
    "    plot_loss_total = 0 \n",
    "    \n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensors_from_pair(input_lang, output_lang, random.choice(pairs)) for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (time_since(start, iter / n_iters), iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "    show_plot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1m 24s (- 19m 45s) (5000 6%) 2.6167\n",
      "2m 49s (- 18m 20s) (10000 13%) 1.0569\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-e4daa49e2038>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_iters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_lang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_lang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_decoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m75000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-21-0d751b63787f>\u001b[0m in \u001b[0;36mtrain_iters\u001b[0;34m(input_lang, output_lang, pairs, encoder, decoder, n_iters, print_every, plot_every, learning_rate)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mtarget_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_pair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mprint_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mplot_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-5ea2085ba026>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m# 把上一步的结果，当做下一步的输入\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0mdecoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_attention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m             \u001b[0mtopv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mdecoder_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtopi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 把上一步预测的top 1 放进去\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-0564f0ce068e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hidden, encoder_outputs)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_iters(input_lang, output_lang, pairs, encoder, attn_decoder, n_iters=75000, print_every=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.load_state_dict(torch.load('./data/encoder.pkl'))\n",
    "attn_decoder.load_state_dict(torch.load('./data/decoder.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seq2seq.eval import evaluate, evaluate_randomly,evaluate_and_show_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 我 生性 樂觀 。\n",
      "= i am an optimist by nature .\n",
      "< i am an optimist by nature . <EOS>\n",
      "\n",
      "> 他 沒 有 他 弟弟 聰明 。\n",
      "= he is not as intelligent as his brother .\n",
      "< he is not as intelligent as his brother . <EOS>\n",
      "\n",
      "> 你們 不再 是 小孩 了 。\n",
      "= you aren't kids anymore .\n",
      "< you aren't kids anymore . <EOS>\n",
      "\n",
      "> 我 厌恶 他 。\n",
      "= i am disgusted with him .\n",
      "< i am disgusted with him . <EOS>\n",
      "\n",
      "> 他 的 职业 是 医生 。\n",
      "= he is a doctor by profession .\n",
      "< he is a doctor by profession . <EOS>\n",
      "\n",
      "> 她 下 週要 去 法國 。\n",
      "= she is going to france next week .\n",
      "< she is going to france next week . <EOS>\n",
      "\n",
      "> 他 是 个 钓鱼 专家 。\n",
      "= he is an expert at fishing .\n",
      "< he is an expert at fishing . <EOS>\n",
      "\n",
      "> 她 像 白雪公主 一樣 漂亮 。\n",
      "= she is as beautiful as snow white .\n",
      "< she is as beautiful as snow white . <EOS>\n",
      "\n",
      "> 他 正在 学 怎么 开车 。\n",
      "= he is learning how to drive a car .\n",
      "< he is learning how to drive a car . <EOS>\n",
      "\n",
      "> 他 是 一個 友善 的 人 。\n",
      "= he is a friendly person .\n",
      "< he is a friendly person . <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_randomly(encoder, attn_decoder, input_lang, output_lang, pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['you', 'are', 'absolutely', 'right', '.', '<EOS>']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 480x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_words, attentions = evaluate(encoder, attn_decoder, input_lang, output_lang, \"你 完全 正確 。\")\n",
    "print(output_words)\n",
    "mat_plot(attentions.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input = 他 对 结果 不 满意 。\n",
      "output = he is unsatisfied with the result . <EOS>\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_and_show_attention(encoder, attn_decoder, input_lang, output_lang, \"他 对 结果 不 满意 。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['他 对 结果 不 满意 。', 'he is unsatisfied with the result .']\n"
     ]
    }
   ],
   "source": [
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
